{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oferta de trabajo comparacion\n",
    "\n",
    "- [ ] Analizar oferta de trabajo para ver elementos destacados\n",
    "- [ ] Estructurar cv usuario 1\n",
    "- [ ] Modelo a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_user = \"1\"\n",
    "datos = {\n",
    "    \"1\":{\n",
    "        \"Person\":{\n",
    "            \"id\":\"1\",\n",
    "            \"name\":\"Luis\",\n",
    "            \"surname\":\"Caumel\",\n",
    "            \"about_me\":\"about me\",\n",
    "            \"birthdata\":\"11-11-1996\",\n",
    "            \"mother_tongue\":\"Spanish\"\n",
    "        },\n",
    "        \"Nationality\": {\n",
    "            \"id_person\":\"1\",\n",
    "            \"value\":\"Spanish\",\n",
    "        },\n",
    "        \"Contact\":{\n",
    "            \"id_person\": \"1\",\n",
    "            \"type_ENUM\": \"mail\",\n",
    "            \"value\":\"luis.caumel@in2ia.com\"\n",
    "        },\n",
    "        \"Address\": {\n",
    "            \"id_person\":\"1\",\n",
    "            \"type_ENUM\":\"home\",\n",
    "            \"line1\":\"C/Calle\",\n",
    "            \"line2\":\"C/Calle\",\n",
    "            \"postal_code\":\"28000\",\n",
    "            \"city\":\"Madrid\",\n",
    "            \"country\":\"Spain\"\n",
    "        },\n",
    "        \"Experience\":[{\n",
    "            \"id_person\":\"1\",\n",
    "            \"position_held\":\"Data Science\",\n",
    "            \"employer\":\"In2AI\",\n",
    "            \"city\":\"Madrid\",\n",
    "            \"country\":\"Spain\",\n",
    "            \"from_date\":\"01-01-2020\",\n",
    "            \"to_date\":\"01-01-2022\",\n",
    "            \"description\":\"description\"\n",
    "        }],\n",
    "        \"Education\":[\n",
    "        {\n",
    "            \"id_person\":\"1\",\n",
    "            \"tittle\":\"Computer Science\",\n",
    "            \"organisation\":\"University\",\n",
    "            \"city\":\"Madrid\",\n",
    "            \"website\":\"www.in2ai.com\",\n",
    "            \"country\":\"Spain\",\n",
    "            \"from_date\":\"\",\n",
    "            \"to_date\":\"01-01-2018\",\n",
    "            \"description\":\"description_1\"\n",
    "        }\n",
    "        ],\n",
    "        \"Language\":[\n",
    "        {\n",
    "            \"id_person\":\"1\",\n",
    "            \"language\":\"Spanish\",\n",
    "            \"listening\":\"Spanish_1\",\n",
    "            \"reading\":\"Spanish_1\",\n",
    "            \"spoken_interaction\":\"interaction\",\n",
    "            \"spoken_production\":\"production\",\n",
    "            \"writing\":\"Spanish_1\"\n",
    "        }\n",
    "        ],\n",
    "        \"Skills\": [\n",
    "        \n",
    "        {\"id_person\":\"1\",\"value\":\"1\",\"description\":\"Python\"},\n",
    "        {\"id_person\":\"1\",\"value\":\"1\",\"description\":\"Java\"}\n",
    "\n",
    "        ],\n",
    "        \"Projects\":[\n",
    "        {\n",
    "            \"id_person\":\"1\",\n",
    "            \"title\":\"Project_1\",\n",
    "            \"from_date\":\"01-01-2018\",\n",
    "            \"to_date\":\"01-01-2018\",\n",
    "            \"description\":\"description\",\n",
    "            \"url\":\"url\"\n",
    "        },\n",
    "        {\n",
    "            \"id_person\":\"1\",\n",
    "            \"title\":\"Project_2\",\n",
    "            \"from_date\":\"01-01-2018\",\n",
    "            \"to_date\":\"01-01-2018\",\n",
    "            \"description\":\"description\",\n",
    "            \"url\":\"url\"\n",
    "        }\n",
    "        ],\n",
    "        \"Licenses\":[\n",
    "        {\n",
    "            \"id_person\":\"1\",\n",
    "            \"type\":\"license_1\"\n",
    "        },\n",
    "        {\n",
    "            \"id_person\":\"1\",\n",
    "            \"type\":\"license_2\"\n",
    "        }\n",
    "        ],\n",
    "        \"Other\":[\n",
    "        {\n",
    "            \"id_person\":\"1\",\n",
    "            \"section_title\":\"section_1\",\n",
    "            \"from_date\":\"01-01-2018\",\n",
    "            \"to_date\":\"01-01-2018\",\n",
    "            \"description\":\"description\",\n",
    "            \"url\":\"url\"\n",
    "        },\n",
    "        {\n",
    "            \"id_person\":\"1\",\n",
    "            \"section_title\":\"section_2\",\n",
    "            \"from_date\":\"01-01-2018\",\n",
    "            \"to_date\":\"01-01-2018\",\n",
    "            \"description\":\"description\",\n",
    "            \"url\":\"url\"\n",
    "        }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.linkedin.com/jobs/search/?currentJobId=3797255515&geoId=100994331&keywords=Recursos%20humanos%20(RR.%C2%A0HH.)&location=Madrid%2C%20Comunidad%20de%20Madrid%2C%20Espa%C3%B1a&origin=JOB_SEARCH_PAGE_LOCATION_AUTOCOMPLETE&refresh=true\n",
    "\n",
    "oferta_en = \"\"\"\n",
    "Who are we?\n",
    "\n",
    "Amaris Consulting is an independent technology consulting firm providing guidance and solutions to businesses. With more than 1,000 clients across the globe, we have been rolling out solutions in major projects for over a decade – this is made possible by an international team of 7,500 people spread across 5 continents and more than 60 countries. Our solutions focus on four different Business Lines: Information System & Digital, Telecom, Life Sciences and Engineering. We’re focused on building and nurturing a top talent community where all our team members can achieve their full potential. Amaris is your steppingstone to cross rivers of change, meet challenges and achieve all your projects with success.\n",
    "\n",
    "At Amaris, we strive to provide our candidates with the best possible recruitment experience. We like to get to know our candidates, challenge them, and be able to give them proper feedback as quickly as possible. Here's what our recruitment process looks like:\n",
    "\n",
    "Brief Call: Our process typically begins with a brief virtual/phone conversation to get to know you! The objective? Learn about you, understand your motivations, and make sure we have the right job for you!\n",
    "\n",
    "Interviews (the average number of interviews is 3 - the number may vary depending on the level of seniority required for the position). During the interviews, you will meet people from our team: your line manager of course, but also other people related to your future role. We will talk in depth about you, your experience, and skills, but also about the position and what will be expected of you. Of course, you will also get to know Amaris: our culture, our roots, our teams, and your career opportunities!\n",
    "\n",
    "Case study: Depending on the position, we may ask you to take a test. This could be a role play, a technical assessment, a problem-solving scenario, etc.\n",
    "\n",
    "As you know, every person is different and so is every role in a company. That is why we have to adapt accordingly, and the process may differ slightly at times. However, please know that we always put ourselves in the candidate's shoes to ensure they have the best possible experience.\n",
    "\n",
    "We look forward to meeting you!\n",
    "\n",
    "Job Description\n",
    "\n",
    "We are currently seeking an entry-level HR Assistant to join our dynamic team in Spain. This role will provide you with a unique opportunity to kickstart your career in human resources within an international consulting group.\n",
    "\n",
    "Assist with day-to-day operations of the HR functions and duties.\n",
    "Provide clerical and administrative support to Human Resources executives.\n",
    "Compile and update employee records (hard and soft copies).\n",
    "Process documentation and prepare reports relating to personnel activities (staffing, recruitment, training, grievances, performance evaluations etc.).\n",
    "Schedule job interviews and assist in interview process.\n",
    "Maintain calendars of HR management team.\n",
    "Orient new employees to the organization (setting up a designated log-in, workstation, email address etc.).\n",
    "Efficiently manage employee questions (trough tickets), providing clear answers and effective solutions.\n",
    "\n",
    "Profile : \n",
    "\n",
    "Master's in business school or in law.\n",
    "Experience in an international company is a plus.\n",
    "Good level of English written and spoken and Portuguese is a plus.\n",
    "Client-oriented, organization, rigor and reliability.\n",
    "Mastery of generative AI (ex: ChatGPT/Poe.com, etc…) is a plus for improving day-to-day productivity.\n",
    "\n",
    "\n",
    "\"Mantu is proud to be an equal opportunity workplace. We are committed to promoting diversity within the workforce and creating an inclusive working environment. For this purpose, we welcome applications from all qualified candidates regardless of gender, sexual orientation, race, ethnicity, beliefs, age, marital status, disability, or other characteristics.\"\n",
    "Aptitudes y experiencia deseables\n",
    "Problem Analysis, Problem Solving, Rigor, Human Resources, Customer oriented\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['who are we', 'amaris consulting is an independent technology consulting firm providing guidance and solutions to businesses with more than  clients across the globe we have been rolling out solutions in major projects for over a decade  this is made possible by an international team of  people spread across  continents and more than  countries our solutions focus on four different business lines information system  digital telecom life sciences and engineering were focused on building and nurturing a top talent community where all our team members can achieve their full potential amaris is your steppingstone to cross rivers of change meet challenges and achieve all your projects with success', 'at amaris we strive to provide our candidates with the best possible recruitment experience we like to get to know our candidates challenge them and be able to give them proper feedback as quickly as possible heres what our recruitment process looks like', 'brief call our process typically begins with a brief virtualphone conversation to get to know you the objective learn about you understand your motivations and make sure we have the right job for you', 'interviews the average number of interviews is   the number may vary depending on the level of seniority required for the position during the interviews you will meet people from our team your line manager of course but also other people related to your future role we will talk in depth about you your experience and skills but also about the position and what will be expected of you of course you will also get to know amaris our culture our roots our teams and your career opportunities', 'case study depending on the position we may ask you to take a test this could be a role play a technical assessment a problemsolving scenario etc', 'as you know every person is different and so is every role in a company that is why we have to adapt accordingly and the process may differ slightly at times however please know that we always put ourselves in the candidates shoes to ensure they have the best possible experience', 'we look forward to meeting you', 'job description', 'we are currently seeking an entrylevel hr assistant to join our dynamic team in spain this role will provide you with a unique opportunity to kickstart your career in human resources within an international consulting group', 'assist with daytoday operations of the hr functions and duties', 'provide clerical and administrative support to human resources executives', 'compile and update employee records hard and soft copies', 'process documentation and prepare reports relating to personnel activities staffing recruitment training grievances performance evaluations etc', 'schedule job interviews and assist in interview process', 'maintain calendars of hr management team', 'orient new employees to the organization setting up a designated login workstation email address etc', 'efficiently manage employee questions trough tickets providing clear answers and effective solutions', 'profile  ', 'masters in business school or in law', 'experience in an international company is a plus', 'good level of english written and spoken and portuguese is a plus', 'clientoriented organization rigor and reliability', 'mastery of generative ai ex chatgptpoecom etc is a plus for improving daytoday productivity', 'mantu is proud to be an equal opportunity workplace we are committed to promoting diversity within the workforce and creating an inclusive working environment for this purpose we welcome applications from all qualified candidates regardless of gender sexual orientation race ethnicity beliefs age marital status disability or other characteristics', 'aptitudes y experiencia deseables', 'problem analysis problem solving rigor human resources customer oriented']\n",
      "['amaris', 'consulting', 'independent', 'technology', 'consulting', 'firm', 'provide', 'guidance', 'solution', 'business', 'client', 'globe', 'roll', 'solution', 'major', 'project', 'decade', 'possible', 'international', 'team', 'people', 'spread', 'continent', 'country', 'solution', 'focus', 'different', 'business', 'line', 'information', 'system', 'digital', 'telecom', 'life', 'science', 'engineering', 'focus', 'build', 'nurture', 'talent', 'community', 'team', 'member', 'achieve', 'potential', 'amaris', 'steppingstone', 'cross', 'river', 'change', 'meet', 'challenge', 'achieve', 'project', 'success']\n",
      "['amaris', 'strive', 'provide', 'candidate', 'good', 'possible', 'recruitment', 'experience', 'like', 'know', 'candidate', 'challenge', 'able', 'proper', 'feedback', 'quickly', 'possible', 'here', 'recruitment', 'process', 'look', 'like']\n",
      "['brief', 'process', 'typically', 'begin', 'brief', 'virtualphone', 'conversation', 'know', 'objective', 'learn', 'understand', 'motivation', 'sure', 'right', 'job']\n",
      "['interview', 'average', 'number', 'interview', '  ', 'number', 'vary', 'depend', 'level', 'seniority', 'require', 'position', 'interview', 'meet', 'people', 'team', 'line', 'manager', 'course', 'people', 'relate', 'future', 'role', 'talk', 'depth', 'experience', 'skill', 'position', 'expect', 'course', 'know', 'amaris', 'culture', 'root', 'team', 'career', 'opportunity']\n",
      "['case', 'study', 'depend', 'position', 'ask', 'test', 'role', 'play', 'technical', 'assessment', 'problemsolving', 'scenario', 'etc']\n",
      "['know', 'person', 'different', 'role', 'company', 'adapt', 'accordingly', 'process', 'differ', 'slightly', 'time', 'know', 'candidate', 'shoe', 'ensure', 'good', 'possible', 'experience']\n",
      "['look', 'forward', 'meet']\n",
      "['job', 'description']\n",
      "['currently', 'seek', 'entrylevel', 'hr', 'assistant', 'join', 'dynamic', 'team', 'spain', 'role', 'provide', 'unique', 'opportunity', 'kickstart', 'career', 'human', 'resource', 'international', 'consulting', 'group']\n",
      "['assist', 'daytoday', 'operation', 'hr', 'function', 'duty']\n",
      "['provide', 'clerical', 'administrative', 'support', 'human', 'resource', 'executive']\n",
      "['compile', 'update', 'employee', 'record', 'hard', 'soft', 'copy']\n",
      "['process', 'documentation', 'prepare', 'report', 'relate', 'personnel', 'activity', 'staff', 'recruitment', 'training', 'grievance', 'performance', 'evaluation', 'etc']\n",
      "['schedule', 'job', 'interview', 'assist', 'interview', 'process']\n",
      "['maintain', 'calendar', 'hr', 'management', 'team']\n",
      "['orient', 'new', 'employee', 'organization', 'set', 'designate', 'login', 'workstation', 'email', 'address', 'etc']\n",
      "['efficiently', 'manage', 'employee', 'question', 'trough', 'ticket', 'provide', 'clear', 'answer', 'effective', 'solution']\n",
      "['profile']\n",
      "['master', 'business', 'school', 'law']\n",
      "['experience', 'international', 'company', 'plus']\n",
      "['good', 'level', 'english', 'write', 'speak', 'portuguese', 'plus']\n",
      "['clientoriente', 'organization', 'rigor', 'reliability']\n",
      "['mastery', 'generative', 'ai', 'ex', 'chatgptpoecom', 'etc', 'plus', 'improve', 'daytoday', 'productivity']\n",
      "['mantu', 'proud', 'equal', 'opportunity', 'workplace', 'committed', 'promote', 'diversity', 'workforce', 'create', 'inclusive', 'working', 'environment', 'purpose', 'welcome', 'application', 'qualified', 'candidate', 'regardless', 'gender', 'sexual', 'orientation', 'race', 'ethnicity', 'belief', 'age', 'marital', 'status', 'disability', 'characteristic']\n",
      "['aptitude', 'y', 'experiencia', 'deseable']\n",
      "['problem', 'analysis', 'problem', 'solve', 'rigor', 'human', 'resource', 'customer', 'orient']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "texto_limpio = re.sub(r'[^a-zA-ZñÑáéíóúÁÉÍÓÚüÜ\\s]', '', oferta_en)  # Remover puntuaciones y caracteres especiales\n",
    "texto_limpio = texto_limpio.lower()\n",
    "\n",
    "result = [line for line in texto_limpio.splitlines( ) if line != '']\n",
    "\n",
    "print(result)\n",
    "\n",
    "texto_limpio = []\n",
    "for linea in result:\n",
    "    doc = nlp(linea)\n",
    "    listas_filtradas = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    listas_filtradas = [element for element in listas_filtradas if element != ' ']\n",
    "    if listas_filtradas:\n",
    "        texto_limpio.append(listas_filtradas)\n",
    "    \n",
    "        print(listas_filtradas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pdfplumber\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import stats\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf2Text(filename):\n",
    "    ''' load pdf and return the text'''\n",
    "    text = ''\n",
    "    # open the pdf file\n",
    "    with pdfplumber.open(filename) as pdfObj:\n",
    "        # loop over each page\n",
    "        for page in pdfObj.pages:\n",
    "            # get text from the page and concat\n",
    "            text += page.extract_text()\n",
    "    # return all texts\n",
    "    return text\n",
    "\n",
    "jd = pdf2Text('../data/dataset/Job description.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(s):\n",
    "    '''Concatenate words like \"D A T A  S C I E N C E\" to get \"DATA SCIENCE\"'''\n",
    "    # add spaces at both end for better processing\n",
    "    s = ' '+s+' '\n",
    "    while True:\n",
    "        # search if more than two alphabets are separated by space\n",
    "        x = re.search(r\"(\\s[a-zA-Z]){2,}\\s\", s)\n",
    "        if x==None:\n",
    "            break\n",
    "        # replace to get the concatenation\n",
    "        s = s.replace(x.group(),' '+x.group().replace(' ','')+' ')\n",
    "    return s\n",
    "\n",
    "def preprocess_text(x, removeStopWords=False):\n",
    "    # convert to lower case\n",
    "    x = re.sub(r'[^a-zA-ZñÑáéíóúÁÉÍÓÚüÜ\\s]', '', x)  # Remover puntuaciones y caracteres especiales\n",
    "    x = str(x).lower()\n",
    "    # replace unusual quotes with '\n",
    "    x = x.replace(\"′\", \"'\").replace(\"’\", \"'\")\n",
    "    # replace new line with space\n",
    "    x = x.replace(\"\\n\", \" \")\n",
    "    # remove links\n",
    "    x = re.sub(r\"http\\S+\", \"\", x)\n",
    "    # convert education degrees like B.Tech or BTech to a specified form\n",
    "    x = re.sub(r\"\\s+b[.]?[ ]?tech[(. /]{1}\", \" btech bachelor of technology \", x)\n",
    "    x = re.sub(r\"\\s+m[.]?[ ]?tech[(. ]{1}\", \" mtech master of technology \", x)\n",
    "    x = re.sub(r\"\\s+b[.]?[ ]?a[(. ]{1}\", \" ba bachelor of arts \", x)\n",
    "    x = re.sub(r\"\\s+m[.]?[ ]?a[(. ]{1}\", \" ma master of arts \", x)\n",
    "    x = re.sub(r\"\\s+b[.]?[ ]?sc[(. ]{1}\", \" bsc bachelor of science \", x)\n",
    "    x = re.sub(r\"\\s+m[.]?[ ]?sc[(. ]{1}\", \" msc master of science \", x)\n",
    "    x = re.sub(r\"\\s+b[.]?[ ]?e[(. ]{1}\", \" beng bachelor of engineering \", x)\n",
    "    x = re.sub(r\"\\s+m[.]?[ ]?e[(. ]{1}\", \" meng master of engineering \", x)\n",
    "    x = re.sub(r\"\\s+b[.]?[ ]?c[.]?[ ]?a[(. ]{1}\", \" bca bachelor of computer applications \", x)\n",
    "    x = re.sub(r\"\\s+m[.]?[ ]?c[.]?[ ]?a[(. ]{1}\", \" mca master of computer applications \", x)\n",
    "    x = re.sub(r\"\\s+b[.]?[ ]?b[.]?[ ]?a[(. ]{1}\", \" bba bachelor of business administration \", x)\n",
    "    x = re.sub(r\"\\s+m[.]?[ ]?b[.]?[ ]?a[(. ]{1}\", \" mba master of business administration \", x)\n",
    "    \n",
    "    # convert skills with special symbols to words\n",
    "    x = x.replace(\"c++\", \"cplusplus\")\n",
    "    x = x.replace(\"c#\", \"csharp\")\n",
    "    x = x.replace(\".net\", \"dotnet\")\n",
    "    \n",
    "    # replace non alpha numeric character with space\n",
    "    x = re.sub('\\W', ' ', x)\n",
    "\n",
    "    x = [line for line in x.splitlines( ) if line != '']\n",
    "\n",
    "    z = []\n",
    "    for linea in x:\n",
    "        doc = nlp(linea)\n",
    "        listas_filtradas = [token.lemma_ for token in doc if not token.is_stop]\n",
    "        listas_filtradas = [element for element in listas_filtradas if element != ' ']\n",
    "        if removeStopWords and listas_filtradas:\n",
    "            z.append(\" \".join(listas_filtradas))\n",
    "\n",
    "    z = ' '.join(z)\n",
    "    z = concat(z)\n",
    "    # strip white spaces\n",
    "    z = z.strip()\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learn engineering abc knowledge innovation ll focus research building designing selfrunne artificial intelligence ai system automate predictive model responsible design create ai algorithm capable learn make prediction define machine learn ml experience qualification bachelor master degree mention course requirement    year work experience provide analytic solution commercial set technical expertise machine learn cluster logistic regression classification different library scikit learn numpy panda matplotlib seaborn deep learn framework tensorflow keras pytorch application neural network model cnn rnn gans familiar natural language processing associate library like nltk spacy beautiful soup pyspark hadoop big datum pipeline datum science methodology exploratory datum analysis feature engineering model selection deployment model scale model evaluation deploy nlp architecture computer vision model production consider plus transformer advance technique nlp familiar computer vision model object detection ocr opencv analytical tool reduce medium data transfer web framework like django database like mongodb nosql graphql sql firebase aw azure google cloud platform job type time\n",
      "amaris consulting independent technology consulting firm provide guidance solution business client globe roll solution major project decade possible international team people spread continent country solution focus different business line information system digital telecom life science engineering focus build nurture talent community team member achieve potential amaris steppingstone cross river change meet challenge achieve project success amaris strive provide candidate good possible recruitment experience like know candidate challenge beng bachelor engineering able proper feedback quickly possible here recruitment process look like brief process typically begin brief virtualphone conversation know objective learn understand motivation sure right job interview average number interview    number vary depend level seniority require position interview meet people team line manager course people relate future role talk depth experience skill position beng bachelor engineering expect course know amaris culture root team career opportunity case study depend position ask test beng bachelor engineering role play technical assessment problemsolving scenario etc know person different role company adapt accordingly process differ slightly time know candidate shoe ensure good possible experience look forward meet job description currently seek entrylevel hr assistant join dynamic team spain role provide unique opportunity kickstart career human resource international consulting group assist daytoday operation hr function duty provide clerical administrative support human resource executive compile update employee record hard soft copy process documentation prepare report relate personnel activity staff recruitment training grievance performance evaluation etc schedule job interview assist interview process maintain calendar hr management team orient new employee organization set designate login workstation email address etc efficiently manage employee question trough ticket provide clear answer effective solution profile     master business school law experience international company plus good level english write speak portuguese plus clientoriented organization rigor reliability mastery generative ai ex chatgptpoecom etc plus improve daytoday productivity    mantu proud beng bachelor engineer equal opportunity workplace committed promote diversity workforce create inclusive working environment purpose welcome application qualified candidate regardless gender sexual orientation race ethnicity belief age marital status disability characteristic aptitude y experiencia deseable problem analysis problem solve rigor human resource customer orient\n"
     ]
    }
   ],
   "source": [
    "\n",
    "jd_processed = preprocess_text(jd, removeStopWords=True)\n",
    "print(jd_processed)\n",
    "cv_processed = preprocess_text(oferta_en, removeStopWords=True)\n",
    "print(cv_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvData = pd.read_csv('../data/dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess all resumes\n",
    "resumes = []\n",
    "for candidateID in csvData.CandidateID.values:\n",
    "    # load resume pdf\n",
    "    resume = pdf2Text('../data/dataset/trainResumes/'+candidateID+'.pdf')\n",
    "    # preprocess\n",
    "    resume_processed = preprocess_text(resume, removeStopWords=True)\n",
    "    resumes.append(resume_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary BoW, TF-IDF,average Word2Vec, Bert based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'job_description': [jd_processed]*len(csvData), 'processed_resume': resumes, 'match_percentage': csvData['Match Percentage']})\n",
    "\n",
    "reputed_colleges = ['bits', 'iit', 'bhu', 'nit', 'vit', 'anna', 'jadavpur', 'tiet', 'thapar', 'iisc', 'srm', 'dtu', 'iiit']\n",
    "\n",
    "# check if is from reputed college\n",
    "def is_from_reputed_college(x):\n",
    "    x = x.split()\n",
    "    for i in reputed_colleges:\n",
    "        if i in x:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def feature_extract(data):\n",
    "    '''extract features'''\n",
    "    # number of words in resume\n",
    "    data['resume_word_num'] = data.processed_resume.apply(lambda x: len(x.split()))\n",
    "    # number of unique words in job description and resumes \n",
    "    data['total_unique_word_num'] = data.apply(lambda x: len(set(x.job_description.split()).union(set(x.processed_resume.split()))) ,axis=1)\n",
    "    # number of common words in job description and resumes\n",
    "    data['common_word_num'] = data.apply(lambda x: len(set(x.job_description.split()).intersection(set(x.processed_resume.split()))) ,axis=1)\n",
    "    # number of common words divided by total number of unique words combined in both job description and resumes\n",
    "    data['common_word_ratio'] = data['common_word_num'] / data.apply(lambda x: len(set(x.job_description.split()).union(set(x.processed_resume.split()))) ,axis=1)\n",
    "    # number of common words divided by minimum number of unique words between job description and resumes\n",
    "    data['common_word_ratio_min'] = data['common_word_num'] / data.apply(lambda x: min(len(set(x.job_description.split())), len(set(x.processed_resume.split()))) ,axis=1) \n",
    "    # number of common words divided by maximum number of unique words between job description and resumes\n",
    "    data['common_word_ratio_max'] = data['common_word_num'] / data.apply(lambda x: max(len(set(x.job_description.split())), len(set(x.processed_resume.split()))) ,axis=1) \n",
    "    \n",
    "    # Fuzz WRatio\n",
    "    data[\"fuzz_ratio\"] = data.apply(lambda x: fuzz.WRatio(x.job_description, x.processed_resume), axis=1)\n",
    "    # Fuzz partial ratio\n",
    "    data[\"fuzz_partial_ratio\"] = data.apply(lambda x: fuzz.partial_ratio(x.job_description, x.processed_resume), axis=1)\n",
    "    # Fuzz token set ratio\n",
    "    data[\"fuzz_token_set_ratio\"] = data.apply(lambda x: fuzz.token_set_ratio(x.job_description, x.processed_resume), axis=1)\n",
    "    # Fuzz token sort ratio\n",
    "    data[\"fuzz_token_sort_ratio\"] = data.apply(lambda x: fuzz.token_sort_ratio(x.job_description, x.processed_resume), axis=1)\n",
    "    \n",
    "    # is fresher\n",
    "    data['is_fresher'] = data.processed_resume.apply(lambda x: int('fresher' in x.split()))\n",
    "    # from reputed college\n",
    "    data['from_reputed_college'] = data.processed_resume.apply(lambda x: is_from_reputed_college(x))\n",
    "    \n",
    "    # fill na fields with 0\n",
    "    data.fillna(0, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n",
      "2024-01-29 12:15:30.541527: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-29 12:15:30.561865: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-29 12:15:30.754441: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-29 12:15:30.756756: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-29 12:15:31.633913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from prettytable import PrettyTable\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# load pretrained models\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "distilbert_model = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = pdf2Text('../data/dataset/Job description.pdf')\n",
    "jd_encoded = tokenizer.encode(jd, max_length=300, padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvData = pd.read_csv('../data/dataset/train.csv')\n",
    "resumes = []\n",
    "for candidateID in csvData.CandidateID.values:\n",
    "    # load resume pdf\n",
    "    resume = pdf2Text('../data/dataset/trainResumes/'+candidateID+'.pdf')\n",
    "    resumes.append(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes_encoded = []\n",
    "for resume in resumes:\n",
    "    # encode with the tokenizer\n",
    "    resume_encoded = tokenizer.encode(resume, max_length=300, padding='max_length', truncation=True)\n",
    "    resumes_encoded.append(resume_encoded)\n",
    "resumes_encoded = np.array(resumes_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get output corresponding to CLS token\n",
    "jd_cls = distilbert_model(np.array([jd_encoded])).last_hidden_state[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "for resume_encoded in resumes_encoded:\n",
    "    # get output corresponding to CLS token\n",
    "    resume_cls = distilbert_model(np.array([resume_encoded])).last_hidden_state[0][0]\n",
    "    X_data.append(tf.concat(axis=0, values = [jd_cls, resume_cls]))\n",
    "X_data = np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 1536)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = csvData['Match Percentage'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x y pair\n",
    "X_data_tf = tf.data.Dataset \\\n",
    "                .from_tensor_slices((X_data, y)) \\\n",
    "                .shuffle(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(.7 * len(X_data_tf))\n",
    "val_size = int(.1 * len(X_data_tf))\n",
    "\n",
    "# get train, cv and test data\n",
    "train_ds = X_data_tf.take(train_size)    \n",
    "val_ds = X_data_tf.skip(train_size).take(val_size)\n",
    "test_ds = X_data_tf.skip(train_size).skip(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batching all the data\n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a FFNN model for BERT outputs\n",
    "inp = tf.keras.layers.Input(shape=(1536,))\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(inp)\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "out = tf.keras.layers.Dense(1, activation='relu')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=out, name='DistilBERT_cls_Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DistilBERT_cls_Regression\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1536)]            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               196736    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 198817 (776.63 KB)\n",
      "Trainable params: 198817 (776.63 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam optimiser and mse loss are set\n",
    "model.compile(optimizer=keras.optimizers.Adam(\n",
    "        learning_rate=1e-7), loss='mse', metrics=['mae'])\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1722.1125 - mae: 38.5240 - val_loss: 1788.5464 - val_mae: 37.5885\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1880.9321 - mae: 40.9411 - val_loss: 1193.3733 - val_mae: 29.2754\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1863.8683 - mae: 40.3657 - val_loss: 1590.4908 - val_mae: 37.2097\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1847.3567 - mae: 40.0635 - val_loss: 1826.1400 - val_mae: 37.3518\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1838.9460 - mae: 39.4951 - val_loss: 1428.5498 - val_mae: 31.4971\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1796.8872 - mae: 39.7094 - val_loss: 1915.9822 - val_mae: 37.7144\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1781.7428 - mae: 39.3613 - val_loss: 1548.7571 - val_mae: 35.0192\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=100,callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 1684.2865 - mae: 37.9078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1684.2864990234375, 37.9078254699707]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 1511.3759 - mae: 35.2443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1511.3758544921875, 35.244327545166016]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 1749.9338 - mae: 38.7084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1749.933837890625, 38.708404541015625]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = pdf2Text('../data/dataset/Job description.pdf')\n",
    "jd_encoded = tokenizer.encode(jd, max_length=300, padding='max_length', truncation=True)\n",
    "resume = pdf2Text('../data/dataset/trainResumes/' + 'candidate_037' + '.pdf')\n",
    "resume_encoded = tokenizer.encode(resume, max_length=300, padding='max_length', truncation=True)\n",
    "jd_cls = distilbert_model(np.array([jd_encoded])).last_hidden_state[0][0]\n",
    "resume_cls = distilbert_model(np.array([resume_encoded])).last_hidden_state[0][0]\n",
    "data = tf.concat(axis=0, values = [jd_cls, resume_cls])\n",
    "data_batch = tf.expand_dims(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5083806]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/models/bert_2024-01-29 10:24:43.812566/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/models/bert_2024-01-29 10:24:43.812566/assets\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def save_model(model,path,_type):\n",
    "    time = str(datetime.now())\n",
    "    path = os.path.join(path,_type + \"_\" + time)\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    model.save(path)\n",
    "    model.save_weights(path + '/weights/')\n",
    "\n",
    "path = '../data/models/'\n",
    "_type = 'bert'\n",
    "# save_model(model,path,_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n",
      "2024-01-30 09:39:30.260921: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-30 09:39:30.274028: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-30 09:39:30.389635: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-30 09:39:30.391029: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-30 09:39:31.148313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from prettytable import PrettyTable\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvData = pd.read_csv('../data/dataset/train.csv')\n",
    "# preprocess all resumes\n",
    "resumes = []\n",
    "for candidateID in csvData.CandidateID.values:  \n",
    "    # load resume pdf\n",
    "    resume = pdf2Text('../data/dataset/trainResumes/'+candidateID+'.pdf')\n",
    "    # preprocess\n",
    "    resume_processed = preprocess_text(resume, removeStopWords=True)\n",
    "    resumes.append(resume_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 13)\n",
      "(90, 15)\n",
      "(90, 640)\n",
      "(90, 640)\n",
      "(90, 15)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "data = pd.DataFrame({'job_description': [jd_processed]*len(csvData), 'processed_resume': resumes, 'match_percentage': csvData['Match Percentage']})\n",
    "\n",
    "def cosine_euclidean(u, v):\n",
    "    return np.array([np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v)), np.linalg.norm(u - v)])\n",
    "\n",
    "reputed_colleges = ['bits', 'iit', 'bhu', 'nit', 'vit', 'anna', 'jadavpur', 'tiet', 'thapar', 'iisc', 'srm', 'dtu', 'iiit']\n",
    "data_feature = feature_extract(data)\n",
    "data_feature.drop(columns=['common_word_ratio', 'common_word_ratio_max'], inplace=True)\n",
    "print(data_feature.shape)\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3), min_df=4, max_df=.99, binary=True)\n",
    "vocab_text = np.unique(np.append(data_feature.processed_resume.values, data_feature.job_description.values))\n",
    "vectorizer.fit(vocab_text)\n",
    "bow_vocab = np.array(list(vectorizer.vocabulary_.keys()))\n",
    "bow_resume = vectorizer.transform(data_feature.processed_resume.values).toarray()\n",
    "bow_jd = vectorizer.transform(data_feature.job_description.values).toarray()\n",
    "cosine_euclidean_data = np.array([cosine_euclidean(bow_jd[i], bow_resume[i]) for i in range(len(bow_resume))])\n",
    "data_feature[[\"cosine_similarity\", \"euclidean_distance\"]] = cosine_euclidean_data\n",
    "print(data_feature.shape)\n",
    "print(bow_resume.shape)\n",
    "print(bow_jd.shape)\n",
    "\n",
    "# data_feature.to_csv('data_feature.csv', index=False)\n",
    "\n",
    "# with open('bow_vocab.npy', 'wb') as f:\n",
    "#     np.save(f, bow_vocab, allow_pickle=True)\n",
    "# with open('bow_resume.npy', 'wb') as f:\n",
    "#     np.save(f, bow_resume, allow_pickle=True)\n",
    "# with open('bow_jd.npy', 'wb') as f:\n",
    "#     np.save(f, bow_jd, allow_pickle=True)\n",
    "\n",
    "data_feature = pd.read_csv('data_feature.csv')\n",
    "print(data_feature.shape)\n",
    "\n",
    "# load bow_resume   \n",
    "with open('bow_resume.npy', 'rb') as f:\n",
    "    bow_resume = np.load(f, allow_pickle=True)\n",
    "\n",
    "# load bow_jd\n",
    "with open('bow_jd.npy', 'rb') as f:\n",
    "    bow_jd = np.load(f, allow_pickle=True)\n",
    "\n",
    "y_bow = data_feature.match_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 12)\n",
      "(90, 640)\n",
      "(90, 640)\n",
      "(90, 1292)\n",
      "Training data size 70% : 63\n",
      "Test data size 30% : 27\n"
     ]
    }
   ],
   "source": [
    "# create_dataset\n",
    "\n",
    "X_bow_1 = data_feature.drop(columns=['job_description', 'processed_resume', 'match_percentage'])\n",
    "X_bow_2 = pd.DataFrame(bow_jd, columns=['bow_jd_'+str(i) for i in range(1, bow_jd.shape[1]+1)])\n",
    "X_bow_3 = pd.DataFrame(bow_resume, columns=['bow_resume_'+str(i) for i in range(1, bow_resume.shape[1]+1)])\n",
    "print(X_bow_1.shape)\n",
    "print(X_bow_2.shape)\n",
    "print(X_bow_3.shape)\n",
    "X_bow = pd.concat([X_bow_1, X_bow_2, X_bow_3], axis=1)\n",
    "print(X_bow.shape)\n",
    "y_bow = data_feature.match_percentage\n",
    "features = X_bow.columns.to_numpy()\n",
    "y_bow = y_bow.to_numpy()\n",
    "# do train test split\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bow, y_bow, test_size=0.30, random_state=1)\n",
    "# get train and test indices\n",
    "train_indices = X_train_bow.index\n",
    "test_indices = X_test_bow.index\n",
    "print('Training data size 70% : '+str(len(X_train_bow)))\n",
    "print('Test data size 30% : '+str(len(X_test_bow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bow_jd_1</th>\n",
       "      <th>bow_jd_2</th>\n",
       "      <th>bow_jd_3</th>\n",
       "      <th>bow_jd_4</th>\n",
       "      <th>bow_jd_5</th>\n",
       "      <th>bow_jd_6</th>\n",
       "      <th>bow_jd_7</th>\n",
       "      <th>bow_jd_8</th>\n",
       "      <th>bow_jd_9</th>\n",
       "      <th>bow_jd_10</th>\n",
       "      <th>...</th>\n",
       "      <th>bow_jd_631</th>\n",
       "      <th>bow_jd_632</th>\n",
       "      <th>bow_jd_633</th>\n",
       "      <th>bow_jd_634</th>\n",
       "      <th>bow_jd_635</th>\n",
       "      <th>bow_jd_636</th>\n",
       "      <th>bow_jd_637</th>\n",
       "      <th>bow_jd_638</th>\n",
       "      <th>bow_jd_639</th>\n",
       "      <th>bow_jd_640</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 640 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bow_jd_1  bow_jd_2  bow_jd_3  bow_jd_4  bow_jd_5  bow_jd_6  bow_jd_7  \\\n",
       "0          0         0         0         0         0         0         0   \n",
       "1          0         0         0         0         0         0         0   \n",
       "2          0         0         0         0         0         0         0   \n",
       "3          0         0         0         0         0         0         0   \n",
       "4          0         0         0         0         0         0         0   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "85         0         0         0         0         0         0         0   \n",
       "86         0         0         0         0         0         0         0   \n",
       "87         0         0         0         0         0         0         0   \n",
       "88         0         0         0         0         0         0         0   \n",
       "89         0         0         0         0         0         0         0   \n",
       "\n",
       "    bow_jd_8  bow_jd_9  bow_jd_10  ...  bow_jd_631  bow_jd_632  bow_jd_633  \\\n",
       "0          0         0          0  ...           0           0           1   \n",
       "1          0         0          0  ...           0           0           1   \n",
       "2          0         0          0  ...           0           0           1   \n",
       "3          0         0          0  ...           0           0           1   \n",
       "4          0         0          0  ...           0           0           1   \n",
       "..       ...       ...        ...  ...         ...         ...         ...   \n",
       "85         0         0          0  ...           0           0           1   \n",
       "86         0         0          0  ...           0           0           1   \n",
       "87         0         0          0  ...           0           0           1   \n",
       "88         0         0          0  ...           0           0           1   \n",
       "89         0         0          0  ...           0           0           1   \n",
       "\n",
       "    bow_jd_634  bow_jd_635  bow_jd_636  bow_jd_637  bow_jd_638  bow_jd_639  \\\n",
       "0            0           0           0           1           0           0   \n",
       "1            0           0           0           1           0           0   \n",
       "2            0           0           0           1           0           0   \n",
       "3            0           0           0           1           0           0   \n",
       "4            0           0           0           1           0           0   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "85           0           0           0           1           0           0   \n",
       "86           0           0           0           1           0           0   \n",
       "87           0           0           0           1           0           0   \n",
       "88           0           0           0           1           0           0   \n",
       "89           0           0           0           1           0           0   \n",
       "\n",
       "    bow_jd_640  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "..         ...  \n",
       "85           1  \n",
       "86           1  \n",
       "87           1  \n",
       "88           1  \n",
       "89           1  \n",
       "\n",
       "[90 rows x 640 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bow_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(feature_selector, n_features_to_select=100, direction='forward', cv=3)\n",
    "sfs.fit(StandardScaler().fit_transform(X_bow), y_bow)\n",
    "features = sfs.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('top_features_bow.npy', 'wb') as f:\n",
    "#     np.save(f, features, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_features_bow.npy', 'rb') as f:\n",
    "    features = np.load(f, allow_pickle=True)\n",
    "X_bow = X_bow.loc[:, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bow, y_bow, test_size=0.30, random_state=1)\n",
    "# get train and test indices\n",
    "train_indices = X_train_bow.index\n",
    "test_indices = X_test_bow.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_bow)\n",
    "X_train_bow = scaler.transform(X_train_bow)\n",
    "X_test_bow = scaler.transform(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bow_jd to file\n",
    "with open('X_train_bow.npy', 'wb') as f:\n",
    "    np.save(f, X_train_bow, allow_pickle=True)\n",
    "with open('y_train_bow.npy', 'wb') as f:\n",
    "    np.save(f, y_train_bow, allow_pickle=True)\n",
    "with open('X_test_bow.npy', 'wb') as f:\n",
    "    np.save(f, X_test_bow, allow_pickle=True)\n",
    "with open('y_test_bow.npy', 'wb') as f:\n",
    "    np.save(f, y_test_bow, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_euclidean(u, v):\n",
    "    return np.array([np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v)), np.linalg.norm(u - v)])\n",
    "\n",
    "\n",
    "def getAverageWord2Vec(sentence,w2v_words,w2v_model):\n",
    "    ''' get Average Word2Vec given a sentence'''\n",
    "    # initialize sentence_vector to zeros\n",
    "    sentence_vector = np.zeros(300)\n",
    "    # count words in sentence\n",
    "    count_words = 0\n",
    "    # loop over each word\n",
    "    for word in sentence.split():\n",
    "        # if there is a vector for given word\n",
    "        if word in w2v_words:\n",
    "            # get the vector\n",
    "            vector = w2v_model[word]\n",
    "            # add the vectors\n",
    "            sentence_vector = sentence_vector + vector\n",
    "            # increment count\n",
    "            count_words = count_words + 1\n",
    "    if count_words != 0:\n",
    "        # if the word count is not zero then divide by it to get the average\n",
    "        sentence_vector /= count_words\n",
    "    # return the avg word2vec\n",
    "    return sentence_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:20<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:44<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# # # Average Word2Vec\n",
    "\n",
    "data_feature2 = data_feature.drop(columns=['cosine_similarity', 'euclidean_distance'])\n",
    "w2v_model = KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "w2v_words = list(w2v_model.key_to_index)\n",
    "\n",
    "# get average word2vec for resumes\n",
    "w2v_resume = []\n",
    "# used tqdm to print progress bar\n",
    "for sentence in tqdm(data_feature2.processed_resume.values):\n",
    "    # get and append sentence vectors\n",
    "    w2v_resume.append(getAverageWord2Vec(sentence,w2v_words,w2v_model))\n",
    "\n",
    "# convert to numpy array\n",
    "w2v_resume = np.array(w2v_resume)\n",
    "print(w2v_resume.shape)\n",
    "# get average word2vec for job description\n",
    "w2v_jd = []\n",
    "for sentence in tqdm(data_feature2.job_description.values):\n",
    "    # get and append sentence vectors\n",
    "    w2v_jd.append(getAverageWord2Vec(sentence,w2v_words,w2v_model))\n",
    "\n",
    "# convert to numpy array\n",
    "w2v_jd = np.array(w2v_jd)\n",
    "cosine_euclidean_data = np.array([cosine_euclidean(w2v_jd[i], w2v_resume[i]) for i in range(len(w2v_resume))])\n",
    "\n",
    "data_feature2[[\"cosine_similarity\", \"euclidean_distance\"]] = cosine_euclidean_data\n",
    "# data_feature2.to_csv('data_feature2.csv', index=False)\n",
    "\n",
    "# # save w2v_resume to file\n",
    "# with open('w2v_resume.npy', 'wb') as f:\n",
    "#     np.save(f, w2v_resume, allow_pickle=True)\n",
    "\n",
    "# with open('w2v_jd.npy', 'wb') as f:\n",
    "#     np.save(f, w2v_jd, allow_pickle=True)\n",
    "\n",
    "data_feature2 = pd.read_csv('data_feature2.csv')\n",
    "\n",
    "with open('w2v_resume.npy', 'rb') as f:\n",
    "    w2v_resume = np.load(f, allow_pickle=True)\n",
    "\n",
    "with open('w2v_jd.npy', 'rb') as f:\n",
    "    w2v_jd = np.load(f, allow_pickle=True)\n",
    "\n",
    "y_w2v = data_feature2.match_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 612)\n",
      "Training data size 70% : 63\n",
      "Test data size 30% : 27\n"
     ]
    }
   ],
   "source": [
    "# create_dataset\n",
    "X_w2v_1 = data_feature2.drop(columns=['job_description', 'processed_resume', 'match_percentage'])\n",
    "X_w2v_2 = pd.DataFrame(w2v_jd, columns=['w2v_jd_'+str(i) for i in range(1, w2v_jd.shape[1]+1)])\n",
    "X_w2v_3 = pd.DataFrame(w2v_resume, columns=['w2v_resume_'+str(i) for i in range(1, w2v_resume.shape[1]+1)])\n",
    "X_w2v = pd.concat([X_w2v_1, X_w2v_2, X_w2v_3], axis=1)\n",
    "print(X_w2v.shape)  \n",
    "y_w2v = data_feature2.match_percentage\n",
    "features = X_w2v.columns.to_numpy()\n",
    "y_w2v = y_w2v.to_numpy()\n",
    "# do train test split\n",
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, y_w2v, test_size=0.30, random_state=1)\n",
    "# get train and test indices\n",
    "train_indices = X_train_w2v.index\n",
    "test_indices = X_test_w2v.index\n",
    "print('Training data size 70% : '+str(len(X_train_w2v)))\n",
    "print('Test data size 30% : '+str(len(X_test_w2v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "feature_selector = Ridge(alpha = 88.197, max_iter=3000)\n",
    "sfs = SequentialFeatureSelector(feature_selector, n_features_to_select=200, direction='forward', cv=3)\n",
    "sfs.fit(StandardScaler().fit_transform(X_w2v), y_w2v)\n",
    "features = X_w2v.columns[sfs.get_support()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('top_features_w2v.npy', 'wb') as f:\n",
    "#     np.save(f, features, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_features_w2v.npy', 'rb') as f:\n",
    "    features = np.load(f, allow_pickle=True)\n",
    "X_w2v = X_w2v[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, y_w2v, test_size=0.30, random_state=1)\n",
    "# get train and test indices\n",
    "train_indices = X_train_w2v.index\n",
    "test_indices = X_test_w2v.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_w2v)\n",
    "X_train_w2v = scaler.transform(X_train_w2v)\n",
    "X_test_w2v = scaler.transform(X_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bow_jd to file\n",
    "with open('X_train_w2v.npy', 'wb') as f:\n",
    "    np.save(f, X_train_w2v, allow_pickle=True)\n",
    "with open('y_train_w2v.npy', 'wb') as f:\n",
    "    np.save(f, y_train_w2v, allow_pickle=True)\n",
    "with open('X_test_w2v.npy', 'wb') as f:\n",
    "    np.save(f, X_test_w2v, allow_pickle=True)\n",
    "with open('y_test_w2v.npy', 'wb') as f:\n",
    "    np.save(f, y_test_bow, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the data\n",
    "with open('X_train_bow.npy', 'rb') as f1, open('X_train_w2v.npy', 'rb') as f2:\n",
    "    X_train = np.concatenate((np.load(f1, allow_pickle=True), np.load(f2, allow_pickle=True)), axis=1)\n",
    "with open('X_test_bow.npy', 'rb') as f1, open('X_test_w2v.npy', 'rb') as f2:\n",
    "    X_test = np.concatenate((np.load(f1, allow_pickle=True), np.load(f2, allow_pickle=True)), axis=1)\n",
    "with open('y_train_bow.npy', 'rb') as f:\n",
    "    y_train = np.load(f, allow_pickle=True)\n",
    "with open('y_test_bow.npy', 'rb') as f:\n",
    "    y_test = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 300)\n",
      "(10, 300)\n",
      "(27, 300)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=.15, random_state=13)\n",
    "print(X_train.shape)\n",
    "print(X_cv.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "\n",
    "# create input-output pair and batch the data.\n",
    "X_train_data = tf.data.Dataset \\\n",
    "                .from_tensor_slices((X_train, y_train)) \\\n",
    "                .batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "X_cv_data = tf.data.Dataset \\\n",
    "                .from_tensor_slices((X_cv, y_cv)) \\\n",
    "                .batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "X_test_data = tf.data.Dataset \\\n",
    "                .from_tensor_slices((X_test, y_test)) \\\n",
    "                .batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple FFNN with TF2 functional API\n",
    "inp = layers.Input(shape=(300,))\n",
    "x = layers.Dense(128, activation='relu')(inp)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "out = layers.Dense(1, activation='relu')(x)\n",
    "model = keras.Model(inputs=inp, outputs=out, name='Bow_avgW2V_Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Bow_avgW2V_Regression\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 300)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               38528     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40609 (158.63 KB)\n",
      "Trainable params: 40609 (158.63 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 33ms/step - loss: 1881.1605 - mae: 40.5089 - val_loss: 1178.0804 - val_mae: 29.7309\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1829.4579 - mae: 39.9177 - val_loss: 1152.2412 - val_mae: 29.3556\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1783.6106 - mae: 39.3850 - val_loss: 1124.7748 - val_mae: 28.9602\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1737.4915 - mae: 38.8474 - val_loss: 1097.7457 - val_mae: 28.5698\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1690.3352 - mae: 38.2928 - val_loss: 1070.6637 - val_mae: 28.1788\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1640.2974 - mae: 37.7009 - val_loss: 1044.1085 - val_mae: 27.7950\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1586.9259 - mae: 37.0603 - val_loss: 1016.7621 - val_mae: 27.3930\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1528.9534 - mae: 36.3568 - val_loss: 988.4635 - val_mae: 26.9725\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1466.5404 - mae: 35.5894 - val_loss: 959.4108 - val_mae: 26.5405\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1398.8977 - mae: 34.7422 - val_loss: 928.6812 - val_mae: 26.0833\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1325.6096 - mae: 33.8047 - val_loss: 896.2306 - val_mae: 25.6016\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1246.4320 - mae: 32.7657 - val_loss: 862.1834 - val_mae: 25.0923\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1162.0476 - mae: 31.6246 - val_loss: 826.8345 - val_mae: 24.5544\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1072.6676 - mae: 30.3701 - val_loss: 789.9477 - val_mae: 23.9797\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 979.0817 - mae: 28.9970 - val_loss: 751.7062 - val_mae: 23.3645\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 882.4247 - mae: 27.5024 - val_loss: 712.6146 - val_mae: 22.7188\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 784.1553 - mae: 25.8856 - val_loss: 672.8936 - val_mae: 22.0428\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 685.8264 - mae: 24.1465 - val_loss: 632.6710 - val_mae: 21.3355\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 589.3434 - mae: 22.2909 - val_loss: 592.1774 - val_mae: 20.5950\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 496.9522 - mae: 20.3303 - val_loss: 551.9522 - val_mae: 19.8266\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 410.6887 - mae: 18.2795 - val_loss: 512.2638 - val_mae: 19.0228\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 332.4942 - mae: 16.1679 - val_loss: 473.8011 - val_mae: 18.1983\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 264.1797 - mae: 14.0576 - val_loss: 437.0873 - val_mae: 17.3611\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 206.7152 - mae: 12.1257 - val_loss: 402.4127 - val_mae: 16.5167\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 160.2480 - mae: 10.4847 - val_loss: 370.4363 - val_mae: 15.6825\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 124.1626 - mae: 9.3209 - val_loss: 341.4715 - val_mae: 14.8919\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 97.0614 - mae: 8.3206 - val_loss: 315.8083 - val_mae: 14.1871\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 77.1373 - mae: 7.3562 - val_loss: 293.6082 - val_mae: 13.5635\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 62.5514 - mae: 6.4322 - val_loss: 274.8494 - val_mae: 13.1499\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 51.6693 - mae: 5.7011 - val_loss: 259.3952 - val_mae: 12.8081\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 43.2391 - mae: 5.1820 - val_loss: 247.0959 - val_mae: 12.5379\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 36.4492 - mae: 4.8015 - val_loss: 237.5566 - val_mae: 12.3271\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 30.7942 - mae: 4.4532 - val_loss: 230.2384 - val_mae: 12.1637\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 26.0089 - mae: 4.1687 - val_loss: 224.7986 - val_mae: 12.0380\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 21.9484 - mae: 3.8699 - val_loss: 220.8962 - val_mae: 11.9419\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 18.5120 - mae: 3.5633 - val_loss: 218.2213 - val_mae: 11.8651\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 15.6070 - mae: 3.2666 - val_loss: 216.4751 - val_mae: 11.8012\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 13.1602 - mae: 2.9773 - val_loss: 215.3388 - val_mae: 11.7432\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 11.1002 - mae: 2.7022 - val_loss: 214.5823 - val_mae: 11.6867\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 9.3708 - mae: 2.4536 - val_loss: 214.0232 - val_mae: 11.6292\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 7.9217 - mae: 2.2341 - val_loss: 213.5330 - val_mae: 11.5696\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 6.7039 - mae: 2.0335 - val_loss: 213.0256 - val_mae: 11.5085\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 5.6800 - mae: 1.8616 - val_loss: 212.4555 - val_mae: 11.4473\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 4.8231 - mae: 1.7223 - val_loss: 211.7997 - val_mae: 11.3864\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 4.1029 - mae: 1.5926 - val_loss: 211.0666 - val_mae: 11.3280\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.4969 - mae: 1.4742 - val_loss: 210.2581 - val_mae: 11.2730\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2.9833 - mae: 1.3676 - val_loss: 209.4137 - val_mae: 11.2228\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.5443 - mae: 1.2644 - val_loss: 208.5650 - val_mae: 11.1784\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.1686 - mae: 1.1672 - val_loss: 207.7518 - val_mae: 11.1405\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8469 - mae: 1.0751 - val_loss: 207.0031 - val_mae: 11.1090\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.5728 - mae: 0.9918 - val_loss: 206.3202 - val_mae: 11.0836\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.3406 - mae: 0.9161 - val_loss: 205.7211 - val_mae: 11.0633\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1451 - mae: 0.8446 - val_loss: 205.2211 - val_mae: 11.0478\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9797 - mae: 0.7776 - val_loss: 204.8144 - val_mae: 11.0361\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8387 - mae: 0.7156 - val_loss: 204.4923 - val_mae: 11.0274\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7182 - mae: 0.6596 - val_loss: 204.2431 - val_mae: 11.0208\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6149 - mae: 0.6067 - val_loss: 204.0539 - val_mae: 11.0156\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5263 - mae: 0.5571 - val_loss: 203.9101 - val_mae: 11.0115\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4502 - mae: 0.5109 - val_loss: 203.8007 - val_mae: 11.0081\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3849 - mae: 0.4681 - val_loss: 203.7135 - val_mae: 11.0051\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3289 - mae: 0.4289 - val_loss: 203.6402 - val_mae: 11.0021\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2808 - mae: 0.3930 - val_loss: 203.5752 - val_mae: 10.9989\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2397 - mae: 0.3599 - val_loss: 203.5127 - val_mae: 10.9957\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2046 - mae: 0.3294 - val_loss: 203.4490 - val_mae: 10.9925\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1746 - mae: 0.3023 - val_loss: 203.3838 - val_mae: 10.9892\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1489 - mae: 0.2772 - val_loss: 203.3180 - val_mae: 10.9860\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1269 - mae: 0.2539 - val_loss: 203.2524 - val_mae: 10.9828\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1081 - mae: 0.2324 - val_loss: 203.1884 - val_mae: 10.9797\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0920 - mae: 0.2125 - val_loss: 203.1269 - val_mae: 10.9767\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0784 - mae: 0.1944 - val_loss: 203.0692 - val_mae: 10.9738\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0667 - mae: 0.1779 - val_loss: 203.0174 - val_mae: 10.9712\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0567 - mae: 0.1626 - val_loss: 202.9731 - val_mae: 10.9690\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0482 - mae: 0.1486 - val_loss: 202.9359 - val_mae: 10.9669\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0410 - mae: 0.1356 - val_loss: 202.9052 - val_mae: 10.9651\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0348 - mae: 0.1238 - val_loss: 202.8809 - val_mae: 10.9635\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0296 - mae: 0.1132 - val_loss: 202.8615 - val_mae: 10.9621\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0252 - mae: 0.1034 - val_loss: 202.8457 - val_mae: 10.9609\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0214 - mae: 0.0945 - val_loss: 202.8327 - val_mae: 10.9597\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0182 - mae: 0.0863 - val_loss: 202.8221 - val_mae: 10.9586\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0155 - mae: 0.0788 - val_loss: 202.8125 - val_mae: 10.9576\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0132 - mae: 0.0719 - val_loss: 202.8042 - val_mae: 10.9568\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0112 - mae: 0.0656 - val_loss: 202.7965 - val_mae: 10.9559\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0096 - mae: 0.0598 - val_loss: 202.7893 - val_mae: 10.9551\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0546 - val_loss: 202.7825 - val_mae: 10.9544\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0069 - mae: 0.0498 - val_loss: 202.7758 - val_mae: 10.9546\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0059 - mae: 0.0454 - val_loss: 202.7691 - val_mae: 10.9547\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0050 - mae: 0.0416 - val_loss: 202.7623 - val_mae: 10.9549\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0380 - val_loss: 202.7558 - val_mae: 10.9549\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0348 - val_loss: 202.7498 - val_mae: 10.9550\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0318 - val_loss: 202.7447 - val_mae: 10.9551\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0027 - mae: 0.0291 - val_loss: 202.7405 - val_mae: 10.9552\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0023 - mae: 0.0266 - val_loss: 202.7370 - val_mae: 10.9552\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0019 - mae: 0.0244 - val_loss: 202.7339 - val_mae: 10.9553\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0017 - mae: 0.0223 - val_loss: 202.7312 - val_mae: 10.9554\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0014 - mae: 0.0204 - val_loss: 202.7289 - val_mae: 10.9554\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 202.7268 - val_mae: 10.9555\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - mae: 0.0171 - val_loss: 202.7253 - val_mae: 10.9555\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 8.8844e-04 - mae: 0.0157 - val_loss: 202.7240 - val_mae: 10.9556\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7.6116e-04 - mae: 0.0144 - val_loss: 202.7229 - val_mae: 10.9556\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.5200e-04 - mae: 0.0131 - val_loss: 202.7218 - val_mae: 10.9557\n"
     ]
    }
   ],
   "source": [
    "# callback to stop execution early if the module is not improving much.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# compile the model with adam optemizer\n",
    "model.compile(optimizer=keras.optimizers.Adam(\n",
    "        learning_rate=1e-3), loss='mse', metrics=['mae'])\n",
    "\n",
    "# training the model\n",
    "history = model.fit(\n",
    "    X_train_data,\n",
    "    validation_data=X_cv_data,\n",
    "    epochs=100,callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show loss curve\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(loss, label='Training MSE')\n",
    "plt.plot(val_loss, label='Validation MSE')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('MSE per Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 222.4899 - mae: 12.0937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[222.4899444580078, 12.093725204467773]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 202.7218 - mae: 10.9557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[202.72177124023438, 10.955659866333008]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_cv, y_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 5.9649e-04 - mae: 0.0123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0005964917363598943, 0.012308759614825249]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = pdf2Text('../data/dataset/Job description.pdf')\n",
    "jd_processed = preprocess_text(jd, removeStopWords=True)\n",
    "resume = pdf2Text('../data/dataset/trainResumes/' + 'candidate_037' + '.pdf')\n",
    "resume = preprocess_text(resume, removeStopWords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 13)\n",
      "(1, 15)\n",
      "(1, 640)\n",
      "(1, 640)\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({'job_description': [jd_processed]*1, 'processed_resume': [resume], 'match_percentage': [None]})\n",
    "def cosine_euclidean(u, v):\n",
    "    return np.array([np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v)), np.linalg.norm(u - v)])\n",
    "\n",
    "reputed_colleges = ['bits', 'iit', 'bhu', 'nit', 'vit', 'anna', 'jadavpur', 'tiet', 'thapar', 'iisc', 'srm', 'dtu', 'iiit']\n",
    "data_feature = feature_extract(data)\n",
    "data_feature.drop(columns=['common_word_ratio', 'common_word_ratio_max'], inplace=True)\n",
    "print(data_feature.shape)\n",
    "vocab_text = np.unique(np.append(data_feature.processed_resume.values, data_feature.job_description.values))\n",
    "bow_vocab = np.array(list(vectorizer.vocabulary_.keys()))\n",
    "bow_resume = vectorizer.transform(data_feature.processed_resume.values).toarray()\n",
    "bow_jd = vectorizer.transform(data_feature.job_description.values).toarray()\n",
    "cosine_euclidean_data = np.array([cosine_euclidean(bow_jd[i], bow_resume[i]) for i in range(len(bow_resume))])\n",
    "data_feature[[\"cosine_similarity\", \"euclidean_distance\"]] = cosine_euclidean_data\n",
    "print(data_feature.shape)\n",
    "print(bow_resume.shape)\n",
    "print(bow_jd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12)\n",
      "(1, 640)\n",
      "(1, 640)\n",
      "(1, 1292)\n"
     ]
    }
   ],
   "source": [
    "X_bow_1 = data_feature.drop(columns=['job_description', 'processed_resume', 'match_percentage'])\n",
    "X_bow_2 = pd.DataFrame(bow_jd, columns=['bow_jd_'+str(i) for i in range(1, bow_jd.shape[1]+1)])\n",
    "X_bow_3 = pd.DataFrame(bow_resume, columns=['bow_resume_'+str(i) for i in range(1, bow_resume.shape[1]+1)])\n",
    "print(X_bow_1.shape)\n",
    "print(X_bow_2.shape)\n",
    "print(X_bow_3.shape)\n",
    "\n",
    "X_bow = pd.concat([X_bow_1, X_bow_2, X_bow_3], axis=1)\n",
    "print(X_bow.shape)\n",
    "features = X_bow.columns.to_numpy()\n",
    "with open('top_features_bow.npy', 'rb') as f:\n",
    "    features = np.load(f, allow_pickle=True)\n",
    "X_bow = X_bow.loc[:, features]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_bow)\n",
    "X_bow = scaler.transform(X_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_euclidean(u, v):\n",
    "    return np.array([np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v)), np.linalg.norm(u - v)])\n",
    "\n",
    "\n",
    "def getAverageWord2Vec(sentence,w2v_words,w2v_model):\n",
    "    ''' get Average Word2Vec given a sentence'''\n",
    "    # initialize sentence_vector to zeros\n",
    "    sentence_vector = np.zeros(300)\n",
    "    # count words in sentence\n",
    "    count_words = 0\n",
    "    # loop over each word\n",
    "    for word in sentence.split():\n",
    "        # if there is a vector for given word\n",
    "        if word in w2v_words:\n",
    "            # get the vector\n",
    "            vector = w2v_model[word]\n",
    "            # add the vectors\n",
    "            sentence_vector = sentence_vector + vector\n",
    "            # increment count\n",
    "            count_words = count_words + 1\n",
    "    if count_words != 0:\n",
    "        # if the word count is not zero then divide by it to get the average\n",
    "        sentence_vector /= count_words\n",
    "    # return the avg word2vec\n",
    "    return sentence_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n"
     ]
    }
   ],
   "source": [
    "data_feature2 = data_feature.drop(columns=['cosine_similarity', 'euclidean_distance'])\n",
    "w2v_model = KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "w2v_words = list(w2v_model.key_to_index)\n",
    "\n",
    "w2v_resume = []\n",
    "for sentence in tqdm(data_feature2.processed_resume.values):\n",
    "    w2v_resume.append(getAverageWord2Vec(sentence,w2v_words,w2v_model))\n",
    "\n",
    "w2v_resume = np.array(w2v_resume)\n",
    "w2v_jd = []\n",
    "for sentence in tqdm(data_feature2.job_description.values):\n",
    "    w2v_jd.append(getAverageWord2Vec(sentence,w2v_words,w2v_model))\n",
    "\n",
    "w2v_jd = np.array(w2v_jd)\n",
    "cosine_euclidean_data = np.array([cosine_euclidean(w2v_jd[i], w2v_resume[i]) for i in range(len(w2v_resume))])\n",
    "\n",
    "data_feature2[[\"cosine_similarity\", \"euclidean_distance\"]] = cosine_euclidean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_dataset\n",
    "X_w2v_1 = data_feature2.drop(columns=['job_description', 'processed_resume', 'match_percentage'])\n",
    "X_w2v_2 = pd.DataFrame(w2v_jd, columns=['w2v_jd_'+str(i) for i in range(1, w2v_jd.shape[1]+1)])\n",
    "X_w2v_3 = pd.DataFrame(w2v_resume, columns=['w2v_resume_'+str(i) for i in range(1, w2v_resume.shape[1]+1)])\n",
    "X_w2v = pd.concat([X_w2v_1, X_w2v_2, X_w2v_3], axis=1)\n",
    "features = X_w2v.columns.to_numpy()\n",
    "with open('top_features_w2v.npy', 'rb') as f:\n",
    "    features = np.load(f, allow_pickle=True)\n",
    "X_w2v = X_w2v[features]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_w2v)\n",
    "X_w2v = scaler.transform(X_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_bow,X_w2v), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
